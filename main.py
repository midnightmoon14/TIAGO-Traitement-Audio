from typing import List, Dict

from tiago_assistant.ollama_client import OllamaClient
from tiago_assistant.stt_micro_only import listen_from_micro


def is_wake(text: str) -> bool:
    """
    Wake word permissif : 'tiago' suffit
    """
    t = (text or "").lower().strip()
    if not t:
        return False
    return "tiago" in t


def run():
    # âš¡ OLLAMA LOCAL â€” modÃ¨le texte humain
    llm = OllamaClient(
        base_url="http://127.0.0.1:11434",
        model="tiago-cesi"  # âš ï¸ TON MODÃˆLE CUSTOM
    )

    # VÃ©rification Ollama
    print("ğŸ” VÃ©rification de la connexion Ollama...")
    try:
        import requests
        r = requests.get("http://127.0.0.1:11434/api/tags", timeout=5)
        r.raise_for_status()
        print("âœ… Ollama accessible")
    except Exception as e:
        print("âŒ Ollama indisponible")
        print(e)
        return

    # ğŸ”¥ Warmup (CRUCIAL)
    print("ğŸ”¥ Warmup du modÃ¨le...")
    try:
        llm.chat_text(
            history=[{"role": "user", "content": "Dis simplement bonjour"}],
            temperature=0.2
        )
        print("âœ… Warmup OK\n")
    except Exception as e:
        print(f"âš ï¸ Warmup Ã©chouÃ© : {e}\n")

    print("=" * 60)
    print("ğŸ¤– TIAGO â€” Assistant vocal CESI")
    print("=" * 60)
    print("ğŸ’¡ Dites Â« Bonjour Tiago Â» pour commencer\n")

    while True:
        # ---- MODE VEILLE ----
        print("ğŸ¤ En attente du wake word...")
        heard = listen_from_micro(
            sample_rate=16000,
            chunk_size=4000,
            timeout_seconds=20.0,
            silence_seconds=3.0
        )

        if not heard:
            continue

        print(f"ğŸ‘‚ Entendu : {heard}")

        if not is_wake(heard):
            continue

        print("âœ… Wake word dÃ©tectÃ©")
        print("ğŸš€ DÃ©marrage de la conversation\n")

        history: List[Dict[str, str]] = []

        # Message d'accueil (DIRECT, HUMAIN)
        greeting = "Bonjour ! Je suis Tiago. Quel est votre projet de formation aujourdâ€™hui ?"
        print(f"ğŸ¤– TIAGO : {greeting}\n")
        history.append({"role": "assistant", "content": greeting})

        # ---- CONVERSATION ----
        while True:
            print("ğŸ¤ Ã€ vous de parler...\n")

            user = listen_from_micro(
                sample_rate=16000,
                chunk_size=4000,
                timeout_seconds=30.0,
                silence_seconds=2.0
            )

            if not user or len(user.strip()) < 3:
                print("âš ï¸ Rien de clair dÃ©tectÃ©, on continue...\n")
                continue

            print(f"ğŸ‘¤ VOUS : {user}\n")
            history.append({"role": "user", "content": user})

            try:
                response = llm.chat_text(
                    history=history,
                    temperature=0.35
                )
            except Exception as e:
                print("âŒ ProblÃ¨me LLM :", e)
                print("ğŸ¤– TIAGO : DÃ©solÃ©, pouvez-vous reformuler ?\n")
                continue

            print(f"ğŸ¤– TIAGO : {response}\n")
            history.append({"role": "assistant", "content": response})


if __name__ == "__main__":
    try:
        run()
    except KeyboardInterrupt:
        print("\nğŸ‘‹ ArrÃªt de Tiago. Ã€ bientÃ´t !")
