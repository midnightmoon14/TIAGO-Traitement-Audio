import time
from typing import List, Dict

from prompts import SYSTEM_PROMPT
from ollama_client import OllamaClient
from stt import STT
from tts import TTS
from validator import validate

DEBUG = True
MAX_CHARS = 220

def dprint(*args):
    if DEBUG:
        print(*args)

def limit_say(text: str) -> str:
    text = (text or "").strip()
    if len(text) <= MAX_CHARS:
        return text
    cut = text[:MAX_CHARS]
    if "." in cut:
        cut = cut.rsplit(".", 1)[0] + "."
    return cut + " â€¦"

def is_wake(text: str) -> bool:
    """
    Wake word plus permissif: juste "tiago" suffit maintenant
    (ou "tiago" + mot de salutation)
    """
    t = (text or "").lower().strip()
    if not t:
        return False
    
    # Accepter juste "tiago" ou "tiago" avec salutation
    if "tiago" in t:
        return True
    
    # Variantes courantes
    wake_words = ["bonjour tiago", "salut tiago", "hey tiago", "coucou tiago", 
                  "bonsoir tiago", "allo tiago", "ok tiago"]
    return any(w in t for w in wake_words)

def run():
    # OPTION 1: Mistral 7B (plus rapide, toujours bon en franÃ§ais)
    llm = OllamaClient(base_url="http://127.0.0.1:11434", model="mistral:7b")
    
    # OPTION 2: Si vous voulez encore plus rapide, essayez Phi-3 mini
    # llm = OllamaClient(base_url="http://127.0.0.1:11434", model="phi3:mini")
    
    # OPTION 3: Pour garder mistral:latest (mais plus lent)
    # llm = OllamaClient(base_url="http://127.0.0.1:11434", model="mistral:latest")
    
    stt = STT(model_size="small", device="cpu", compute_type="int8")
    tts = TTS(rate=175)

    print("=" * 60)
    print("ðŸ¤– TIAGO - Assistant vocal CESI")
    print("=" * 60)
    
    # CALIBRATION AUTOMATIQUE AU DÃ‰MARRAGE
    stt.calibrate_volume(duration=3.0)
    
    print("âœ… TIAGO est prÃªt !")
    print("ðŸ’¡ Dites 'Bonjour Tiago' ou 'Hey Tiago' pour commencer.\n")

    while True:
        # ---- WAKE MODE ----
        print("ðŸŽ¤ En attente du wake word...")
        heard = stt.listen(seconds=3.0, skip_volume_check=False, show_volume=DEBUG)
        
        if heard:
            print(f"ðŸ‘‚ DÃ©tectÃ©: '{heard}'")
        
        if not heard or len(heard.strip()) < 2:
            continue

        # VÃ©rifier si c'est le wake word
        if is_wake(heard):
            print(f"âœ… Wake word dÃ©tectÃ©: '{heard}'")
            print("ðŸš€ DÃ©marrage de la conversation...\n")
            
            # IMPORTANT: petite pause avant que Tiago parle
            time.sleep(0.5)
            
            tts.say("Bonjour ! Je suis Tiago. Je peux vous aider Ã  trouver la formation CESI la plus adaptÃ©e. Qu'est-ce que vous recherchez ?")
            
            # CRUCIAL: attendre que le TTS finisse + 2 secondes de pause
            # pour Ã©viter que le micro capte la fin de la voix de Tiago
            time.sleep(2.0)

            history: List[Dict[str, str]] = []
            conversation_active = True

            while conversation_active:
                print("\nðŸŽ¤ Ã€ vous de parler (vous avez 8 secondes)...")
                
                # Ã‰coute avec feedback visuel
                user = stt.listen(seconds=8.0, show_volume=DEBUG)
                
                if user:
                    print(f"âœ… Vous avez dit: '{user}'\n")
                else:
                    print("âš ï¸  Rien dÃ©tectÃ© ou volume trop faible")

                # Si silence ou texte trop court
                if not user or len(user.strip()) < 3:
                    print("âš ï¸  Texte trop court, je demande de rÃ©pÃ©ter...\n")
                    tts.say("Je n'ai pas bien entendu. Pouvez-vous rÃ©pÃ©ter un peu plus fort ?")
                    time.sleep(2.0)  # Pause aprÃ¨s TTS
                    continue

                print(f"[USER] {user}")
                history.append({"role": "user", "content": user})

                # Appel au LLM avec DEBUG DÃ‰TAILLÃ‰
                try:
                    print("ðŸ”„ Envoi au LLM Mistral...")
                    print(f"   ðŸ“ Historique: {len(history)} messages")
                    
                    obj = llm.chat_json(SYSTEM_PROMPT, history, temperature=0.2)
                    
                    print(f"âœ… RÃ©ponse LLM reÃ§ue: {obj}")
                    print("ðŸ” Validation en cours...")
                    
                    validate(obj)
                    
                    print("âœ… Validation OK")
                    dprint("[LLM-JSON]", obj)
                    
                except Exception as e:
                    print(f"âŒ ERREUR DÃ‰TAILLÃ‰E:")
                    print(f"   Type: {type(e).__name__}")
                    print(f"   Message: {e}")
                    import traceback
                    traceback.print_exc()
                    
                    tts.say("DÃ©solÃ©, j'ai eu un problÃ¨me technique. Pouvez-vous reformuler ?")
                    time.sleep(2.0)
                    continue

                # PrÃ©parer la rÃ©ponse
                say = limit_say(obj.get("say", ""))
                if not say:
                    say = "D'accord. Pouvez-vous prÃ©ciser votre niveau actuel et votre objectif ?"

                print(f"[TIAGO] {say}\n")
                tts.say(say)
                
                # CRUCIAL: pause aprÃ¨s chaque rÃ©ponse de Tiago
                time.sleep(2.0)

                # Historique assistant
                history.append({"role": "assistant", "content": str(obj)})

                # VÃ©rifier si terminÃ©
                if obj.get("done") is True and obj.get("dataset") is not None:
                    print("\n" + "=" * 60)
                    print("ðŸ“Š DATASET FINAL")
                    print("=" * 60)
                    print(obj["dataset"])
                    print("=" * 60 + "\n")
                    
                    tts.say("Merci ! Bonne visite au CESI Bordeaux. Ã€ bientÃ´t !")
                    time.sleep(2.0)
                    
                    print("ðŸ”„ Retour au mode veille.")
                    print("ðŸ’¡ Dites 'Bonjour Tiago' pour recommencer.\n")
                    conversation_active = False
                    break

if __name__ == "__main__":
    try:
        run()
    except KeyboardInterrupt:
        print("\n\nðŸ‘‹ ArrÃªt de Tiago. Ã€ bientÃ´t !")
    except Exception as e:
        print(f"\nâŒ Erreur fatale: {e}")
        raise