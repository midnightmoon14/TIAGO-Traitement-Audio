# ğŸ¤– TIAGO - Assistant Vocal JPO CESI Bordeaux

Documentation complÃ¨te du projet - Version Janvier 2025

---

## ğŸ“‹ TABLE DES MATIÃˆRES

1. [Vue d'ensemble](#vue-densemble)
2. [Architecture du systÃ¨me](#architecture-du-systÃ¨me)
3. [Installation](#installation)
4. [Configuration](#configuration)
5. [Utilisation](#utilisation)
6. [Structure des fichiers](#structure-des-fichiers)
7. [API et IntÃ©gration](#api-et-intÃ©gration)
8. [DÃ©pannage](#dÃ©pannage)
9. [SpÃ©cifications techniques](#spÃ©cifications-techniques)

---

## ğŸ¯ VUE D'ENSEMBLE

### Objectif
TIAGO est un assistant vocal intelligent pour la JournÃ©e Portes Ouvertes du CESI Bordeaux. Il guide les visiteurs vers la formation la plus adaptÃ©e Ã  leur profil.

### FonctionnalitÃ©s
- âœ… **DÃ©tection vocale** (wake word : "Bonjour Tiago")
- âœ… **Conversation naturelle** en franÃ§ais et anglais
- âœ… **Recommandation intelligente** de formations
- âœ… **SynthÃ¨se vocale** de qualitÃ© (Google TTS)
- âœ… **Dataset final** avec couleur de brochure

### Les 4 formations CESI
| Formation | Couleur | Public | Objectif |
|-----------|---------|--------|----------|
| **Programme Grande Ecole** | ğŸŸ¡ JAUNE | LycÃ©ens/Bac+2/3 | DiplÃ´me ingÃ©nieur Bac+5 |
| **Bachelor De Specialite** | ğŸ”µ BLEU | LycÃ©ens | Bac+3 professionnel |
| **Master Professionnel** | ğŸ”´ ROUGE | Bac+3/4 | SpÃ©cialisation Bac+5 |
| **Programme Executive** | ğŸŸ¢ VERT | Professionnels | Formation continue |

---

## ğŸ—ï¸ ARCHITECTURE DU SYSTÃˆME

### Pipeline complet

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. WAKE WORD DETECTION                                     â”‚
â”‚     Ã‰coute continue â†’ "Bonjour Tiago" dÃ©tectÃ©              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. SPEECH-TO-TEXT (STT)                                    â”‚
â”‚     Audio â†’ Whisper (faster-whisper) â†’ Texte franÃ§ais      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3. LANGUAGE MODEL (LLM)                                    â”‚
â”‚     Texte â†’ Ollama (local) â†’ JSON structurÃ©                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  4. TEXT-TO-SPEECH (TTS)                                    â”‚
â”‚     Texte â†’ Google TTS â†’ Audio                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  5. OUTPUT JSON                                             â”‚
â”‚     {"couleur": "jaune", "quantite": 1} â†’ Action robot     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Composants principaux

| Composant | Technologie | RÃ´le |
|-----------|------------|------|
| **STT** | Faster Whisper (small) | Transcription audio â†’ texte |
| **LLM** | Ollama (llama3.2:3b ou phi3:mini) | Intelligence conversationnelle locale |
| **TTS** | Google Text-to-Speech | SynthÃ¨se vocale naturelle |
| **Validation** | Python JSON Schema | VÃ©rification format de sortie |

---

## ğŸ’» INSTALLATION

### PrÃ©requis
- **Python 3.12+**
- **Windows 10/11** (ou Linux/macOS)
- **8 GB RAM minimum** (16 GB recommandÃ© pour Ollama)
- **Connexion internet** (pour Google TTS uniquement)

### Ã‰tape 1 : Cloner le projet
```bash
git clone <votre-repo>
cd tiag
```

### Ã‰tape 2 : Installer les dÃ©pendances
```bash
pip install -r requirements.txt
```

**Contenu de `requirements.txt` :**
```
faster-whisper
pyaudio
numpy
gtts
pygame
requests
```

### Ã‰tape 3 : Installer Ollama (requis pour LLM local)
```bash
# Windows
winget install Ollama.Ollama

# TÃ©lÃ©charger un modÃ¨le lÃ©ger et rapide (recommandÃ©)
ollama pull llama3.2:3b

# Ou alternatives :
# ollama pull phi3:mini      # Excellent en franÃ§ais
# ollama pull qwen2:1.5b     # Le plus lÃ©ger
```

---

## âš™ï¸ CONFIGURATION

### Configuration du micro

**1. Lister les micros disponibles :**
```bash
python list_audio_devices.py
```

**2. Configurer dans `main.py` :**
```python
MICRO_INDEX = 1  # Changez selon votre micro
stt = STT(
    model_size="small",
    device="cpu",
    compute_type="int8",
    input_device_index=MICRO_INDEX
)
```

### Configuration du LLM

**Ollama local (illimitÃ©, ~5-15s/rÃ©ponse selon modÃ¨le) :**
```python
from tiago_assistant.ollama_client import OllamaClient

# ModÃ¨le recommandÃ© : llama3.2:3b (Ã©quilibre vitesse/qualitÃ©)
llm = OllamaClient(
    base_url="http://127.0.0.1:11434",
    model="llama3.2:3b"
)

# Alternatives :
# model="phi3:mini"      # Excellent en franÃ§ais
# model="qwen2:1.5b"     # Le plus lÃ©ger et rapide
```

### ParamÃ¨tres ajustables

| ParamÃ¨tre | Fichier | Ligne | Description |
|-----------|---------|-------|-------------|
| DurÃ©e Ã©coute | `main.py` | ~110 | `seconds=5.0` (timeout Ã©coute) |
| Seuil volume | `stt.py` | ~70 | `volume_threshold` (sensibilitÃ© micro) |
| Wake word | `main.py` | ~30 | Fonction `is_wake()` |
| TempÃ©rature LLM | `main.py` | ~125 | `temperature=0.2` (crÃ©ativitÃ©) |
| Vitesse TTS | N/A | N/A | Google TTS = vitesse fixe |

---

## ğŸš€ UTILISATION

### Lancement basique
```bash
python main.py
```

### Flux d'interaction

**1. DÃ©marrage :**
```
ğŸ”§ Calibration du micro (2 secondes de silence)
âœ… TIAGO prÃªt !
ğŸ¤ En attente du wake word...
```

**2. Activation :**
```
Vous : "Bonjour Tiago"
âœ… Wake word dÃ©tectÃ© !
Tiago : "Bonjour ! Comment je peux vous aider ?"
```

**3. Conversation :**
```
Vous : "Je cherche une formation en informatique"
Tiago : "Super ! Quel est votre niveau : lycÃ©e, bac+2 ou bac+3 ?"

Vous : "Je suis en terminale"
Tiago : "Parfait ! Vous visez ingÃ©nieur ou bac+3 ?"

Vous : "IngÃ©nieur"
Tiago : "Le Programme Grande Ã‰cole est idÃ©al pour vous. IntÃ©ressÃ© ?"

Vous : "Oui"
Tiago : "GÃ©nial ! Bonne visite au CESI Bordeaux."
ğŸ“Š DATASET FINAL : {"couleur": "jaune", "quantite": 1}
```

### ArrÃªt
- Appuyez sur `Ctrl+C` pour arrÃªter proprement

---

## ğŸ“ STRUCTURE DES FICHIERS

```
tiag/
â”œâ”€â”€ main.py                     # Orchestration principale
â”œâ”€â”€ stt.py                      # Speech-to-Text (Whisper)
â”œâ”€â”€ tts_gtts.py                 # Text-to-Speech (Google)
â”œâ”€â”€ prompts.py                  # Prompt systÃ¨me LLM
â”œâ”€â”€ validator.py                # Validation JSON
â”œâ”€â”€ ollama_client.py            # Client Ollama (local uniquement)
â”œâ”€â”€ list_audio_devices.py       # Utilitaire liste micros
â”œâ”€â”€ requirements.txt            # DÃ©pendances Python
â”œâ”€â”€ DOCUMENTATION.md            # Ce fichier
â””â”€â”€ .gitignore                  # Fichiers ignorÃ©s par Git
```

### Description des fichiers

#### `main.py`
Fichier principal qui orchestre :
- Calibration du micro
- DÃ©tection wake word
- Boucle de conversation
- Gestion historique
- Validation et output final

#### `stt.py`
Classe `STT` pour la transcription audio :
- Initialisation Whisper (faster-whisper)
- Calibration automatique du seuil de volume
- Filtrage VAD (Voice Activity Detection)
- Nettoyage transcriptions (pas de langue asiatique, etc.)

#### `tts_gtts.py`
Classe `TTS` pour la synthÃ¨se vocale :
- Google Text-to-Speech (gTTS)
- DÃ©tection automatique franÃ§ais/anglais
- Lecture audio avec pygame
- Correction prononciation ("CESI" â†’ "Saisie")

#### `prompts.py`
Prompt systÃ¨me pour le LLM :
- Description des 4 formations
- Arbre de dÃ©cision
- Format JSON strict
- Exemples de conversations
- RÃ¨gles conversationnelles

#### `validator.py`
Validation du JSON retournÃ© par le LLM :
- VÃ©rification des champs obligatoires
- Validation couleurs/labels autorisÃ©s
- CohÃ©rence done/dataset/proposed

#### `ollama_client.py`
Client pour Ollama (LLM local) :
- Communication avec serveur local
- Extraction et nettoyage JSON
- Tentative de rÃ©paration si JSON invalide
- Debug et logs

---

## ğŸ”Œ API ET INTÃ‰GRATION

### Pour intÃ©grer au robot

Le robot appelle votre code comme un **module Python** :

```python
# robot_main.py (code du robot)
from main import TiagoAssistant  # Ã€ crÃ©er

tiago = TiagoAssistant()

# DÃ©marrer conversation
response = tiago.start_conversation()
robot.speak(response['say'])

# Boucle conversation
while True:
    audio = robot.record_audio(seconds=5)
    response = tiago.process_turn(audio)
    
    robot.speak(response['say'])
    
    if response['done']:
        couleur = response['dataset']['couleur']
        robot.take_brochure(couleur)
        break
```

### Format JSON de sortie

**Structure complÃ¨te :**
```json
{
  "say": "Texte que le robot doit dire (max 25 mots)",
  "done": false,
  "ask_confirmation": false,
  "proposed": null,
  "dataset": null,
  "handoff": false
}
```

**Quand une formation est proposÃ©e :**
```json
{
  "say": "Le Programme Grande Ã‰cole est parfait pour vous. IntÃ©ressÃ© ?",
  "done": false,
  "ask_confirmation": true,
  "proposed": {
    "label": "Programme Grande Ecole",
    "couleur": "jaune"
  },
  "dataset": null,
  "handoff": false
}
```

**Quand conversation terminÃ©e (dataset final) :**
```json
{
  "say": "GÃ©nial ! Bonne visite au CESI Bordeaux.",
  "done": true,
  "ask_confirmation": false,
  "proposed": {
    "label": "Programme Grande Ecole",
    "couleur": "jaune"
  },
  "dataset": {
    "couleur": "jaune",
    "quantite": 1
  },
  "handoff": false
}
```

**Quand question hors sujet :**
```json
{
  "say": "Je ne connais pas les tarifs. L'Ã©quipe vous renseignera !",
  "done": false,
  "ask_confirmation": false,
  "proposed": null,
  "dataset": null,
  "handoff": true
}
```

---

## ğŸ”§ DÃ‰PANNAGE

### ProblÃ¨me : Calibration Ã  0

**SymptÃ´me :**
```
ğŸ“Š Bruit ambiant: 0
ğŸ¯ Seuil de dÃ©tection: 1
```

**Causes possibles :**
- Micro non branchÃ©
- Micro dÃ©sactivÃ© dans Windows
- Mauvais index de micro

**Solutions :**
1. VÃ©rifiez : ParamÃ¨tres Windows â†’ Son â†’ EntrÃ©e
2. Testez le micro (la barre doit bouger quand vous parlez)
3. Listez les micros : `python list_audio_devices.py`
4. Changez `MICRO_INDEX` dans `main.py`

---

### ProblÃ¨me : LLM ne rÃ©pond pas en JSON

**SymptÃ´me :**
```
âš ï¸  ValueError: No JSON found in model output
```

**Causes :**
- Prompt trop long (Mistral 7B se perd)
- ModÃ¨le ne comprend pas les instructions
- TempÃ©rature trop Ã©levÃ©e

**Solutions :**
1. Utilisez un modÃ¨le plus rÃ©cent : `llama3.2:3b` ou `phi3:mini`
2. RÃ©duisez la tempÃ©rature : `temperature=0.1`
3. Simplifiez le prompt (dÃ©jÃ  optimisÃ© dans `prompts.py`)
4. VÃ©rifiez qu'Ollama est bien dÃ©marrÃ© : `ollama serve`

---

---

### ProblÃ¨me : TTS n'a pas de voix franÃ§aise

**SymptÃ´me :**
```
âš ï¸  Aucune voix franÃ§aise trouvÃ©e
```

**Solution (tts_gtts.py - dÃ©jÃ  en place) :**
Google TTS utilise automatiquement une voix franÃ§aise de qualitÃ©. Pas besoin de configuration.

---

### ProblÃ¨me : PyAudio installation failed

**SymptÃ´me :**
```
ERROR: Could not build wheels for pyaudio
```

**Solution Windows :**
```bash
pip install pipwin
pipwin install pyaudio
```

**Solution alternative :**
TÃ©lÃ©chargez le wheel : https://www.lfd.uci.edu/~gohlke/pythonlibs/#pyaudio
```bash
pip install PyAudioâ€‘0.2.11â€‘cp312â€‘cp312â€‘win_amd64.whl
```

---

## ğŸ“Š SPÃ‰CIFICATIONS TECHNIQUES

### Performance

| MÃ©trique | Valeur | Notes |
|----------|--------|-------|
| **Latence STT** | 1-2s | Whisper small sur CPU |
| **Latence LLM (Ollama)** | 5-15s | Local, dÃ©pend du modÃ¨le et CPU |
| **Latence TTS** | 1-2s | Google TTS + pygame |
| **Latence totale** | 8-20s | Par tour de parole |


### Limitations

| Limite | Valeur | Contournement |
|--------|--------|---------------|
| **RequÃªtes Ollama** | IllimitÃ©es | Local uniquement |
| **DurÃ©e Ã©coute max** | 5s | Ajustable dans code |
| **Langues supportÃ©es** | FR, EN | Extensible (prompt) |
| **Wake words** | "Bonjour/Hey Tiago" | Modifiable (`is_wake()`) |

### ModÃ¨les utilisÃ©s

| Composant | ModÃ¨le | Taille | Notes |
|-----------|--------|--------|-------|
| **STT** | Whisper Small | 244 MB | Bon compromis vitesse/qualitÃ© |
| **LLM (Ollama)** | llama3.2:3b | ~2 GB | RecommandÃ© : rapide et bon en franÃ§ais |
| **LLM (Ollama)** | phi3:mini | ~2.3 GB | Alternative : excellent en franÃ§ais |
| **LLM (Ollama)** | qwen2:1.5b | ~1 GB | Le plus lÃ©ger et rapide |
| **TTS** | Google TTS | Cloud | Voix naturelle FR/EN |

---

## ğŸ“ NOTES IMPORTANTES

### Prononciation "CESI"
Le systÃ¨me remplace automatiquement "CESI" par "Saisie" pour une prononciation correcte en franÃ§ais.

### Gestion conversation
- Une conversation = 1 visiteur
- Historique conservÃ© pendant la conversation
- Reset automatique aprÃ¨s `done: true`

### SÃ©curitÃ©
- Pas de stockage des conversations
- Pas de donnÃ©es personnelles collectÃ©es
- ClÃ©s API Ã  garder secrÃ¨tes (`.gitignore`)

### Maintenance
- Mise Ã  jour Ollama : `ollama pull llama3.2:3b`
- Mise Ã  jour dÃ©pendances : `pip install -U -r requirements.txt`
- Logs en temps rÃ©el dans le terminal
- VÃ©rifier qu'Ollama tourne : `ollama list`

---





{
    "say": "Super ! Vous visez ingÃ©nieur ou bac+3 ?",  â† TEXTE pour le TTS
    "done": False,                                      â† Conversation finie ?
    "ask_confirmation": False,
    "proposed": None,
    "dataset": None,                                    â† Brochure (si done=True)
    "handoff": False
}



