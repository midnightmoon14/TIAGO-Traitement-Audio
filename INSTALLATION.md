# üì¶ Guide d'Installation - TIAGO Assistant Vocal

## Pr√©requis

- **Python 3.12+** (recommand√©) ou Python 3.10+
- **Windows 10/11** (ou Linux/macOS)
- **8 GB RAM minimum** (16 GB recommand√© pour Ollama)
- **Connexion internet** (pour t√©l√©charger les mod√®les et Google TTS)

---

## √âtape 1 : Installer Python

### Windows
1. T√©l√©chargez Python depuis https://www.python.org/downloads/
2. **IMPORTANT** : Cochez "Add Python to PATH" lors de l'installation
3. V√©rifiez l'installation :
```bash
python --version
# Doit afficher Python 3.10 ou sup√©rieur
```

### Linux/macOS
```bash
# Ubuntu/Debian
sudo apt update && sudo apt install python3 python3-pip

# macOS (avec Homebrew)
brew install python3
```

---

## √âtape 2 : Installer les d√©pendances Python

### Option A : Installation automatique (recommand√©)
```bash
# Depuis le dossier du projet
pip install -r requirements.txt
```

### Option B : Installation manuelle
```bash
pip install requests>=2.31.0
pip install faster-whisper>=1.0.0
pip install numpy>=1.24.0
pip install pyaudio>=0.2.11
pip install gtts>=2.5.0
```

### ‚ö†Ô∏è Probl√®me avec PyAudio sur Windows ?

Si `pip install pyaudio` √©choue :

**Solution 1 : Utiliser pipwin**
```bash
pip install pipwin
pipwin install pyaudio
```

**Solution 2 : T√©l√©charger le wheel**
1. Allez sur https://www.lfd.uci.edu/~gohlke/pythonlibs/#pyaudio
2. T√©l√©chargez le fichier correspondant √† votre version Python (ex: `PyAudio-0.2.11-cp312-cp312-win_amd64.whl`)
3. Installez-le :
```bash
pip install PyAudio-0.2.11-cp312-cp312-win_amd64.whl
```

---

## √âtape 3 : Installer Ollama

Ollama est **requis** pour le LLM local. Il ne s'installe pas via pip.

### Windows
```bash
# M√©thode 1 : Winget (recommand√©)
winget install Ollama.Ollama

# M√©thode 2 : T√©l√©chargement manuel
# Allez sur https://ollama.com/download
# T√©l√©chargez et installez Ollama pour Windows
```

### Linux
```bash
curl -fsSL https://ollama.com/install.sh | sh
```

### macOS
```bash
# M√©thode 1 : Homebrew
brew install ollama

# M√©thode 2 : T√©l√©chargement manuel
# Allez sur https://ollama.com/download
```

### V√©rifier l'installation
```bash
ollama --version
# Doit afficher la version d'Ollama
```

### D√©marrer Ollama
```bash
# Windows : Ollama d√©marre automatiquement apr√®s l'installation
# Si ce n'est pas le cas :
ollama serve

# Linux/macOS :
ollama serve
```

Ollama tourne sur `http://127.0.0.1:11434` par d√©faut.

---

## √âtape 4 : T√©l√©charger un mod√®le Ollama

Vous devez t√©l√©charger au moins un mod√®le pour que le syst√®me fonctionne.

### Mod√®les recommand√©s (par ordre de vitesse)

**1. Mod√®le rapide (recommand√© pour d√©buter) :**
```bash
ollama pull llama3.2:3b
```

**2. Mod√®le √©quilibr√© (bon compromis) :**
```bash
ollama pull llama3.1:8b-q4_K_M
# Version quantifi√©e, 2x plus rapide que la version normale
```

**3. Mod√®le complet (meilleure qualit√©, plus lent) :**
```bash
ollama pull llama3.1:8b
```

**4. Mod√®le tr√®s l√©ger (le plus rapide) :**
```bash
ollama pull qwen2:1.5b
```

### V√©rifier les mod√®les install√©s
```bash
ollama list
```

### Changer de mod√®le dans le code
Modifiez `main.py` ligne 43 :
```python
llm = OllamaClient(base_url="http://127.0.0.1:11434", model="llama3.2:3b")
```

---

## √âtape 5 : V√©rifier l'installation

### Test rapide
```bash
# Test Python
python --version

# Test Ollama
ollama list

# Test des d√©pendances Python
python -c "import requests, numpy, faster_whisper, pyaudio; print('‚úÖ Toutes les d√©pendances sont install√©es')"
```

### Test complet du projet
```bash
python main.py
```

Si tout fonctionne, vous devriez voir :
```
============================================================
ü§ñ TIAGO - Assistant vocal CESI
============================================================
üîß Chargement du mod√®le Whisper...
üîß Calibration micro (2 secondes)...
‚úÖ TIAGO est pr√™t !
```

---

## D√©pannage

### Ollama ne d√©marre pas
```bash
# Windows : V√©rifiez dans le Gestionnaire des t√¢ches
# Linux/macOS : V√©rifiez les processus
ps aux | grep ollama

# Red√©marrer Ollama
ollama serve
```

### Erreur "Module not found"
```bash
# R√©installer toutes les d√©pendances
pip install --upgrade -r requirements.txt
```

### Microphone non d√©tect√©
1. **Windows** : Param√®tres ‚Üí Son ‚Üí Entr√©e ‚Üí Testez votre micro
2. V√©rifiez que le micro n'est pas utilis√© par une autre application
3. Listez les micros disponibles :
```bash
python -c "import pyaudio; p = pyaudio.PyAudio(); [print(f'{i}: {p.get_device_info_by_index(i)[\"name\"]}') for i in range(p.get_device_count())]"
```

### Mod√®le Ollama trop lent
- Utilisez une version quantifi√©e : `llama3.1:8b-q4_K_M`
- Ou un mod√®le plus petit : `llama3.2:3b`
- V√©rifiez vos ressources CPU/RAM

---

## Structure des fichiers apr√®s installation

```
tiag/
‚îú‚îÄ‚îÄ main.py
‚îú‚îÄ‚îÄ requirements.txt          ‚Üê Ce fichier
‚îú‚îÄ‚îÄ INSTALLATION.md           ‚Üê Ce guide
‚îú‚îÄ‚îÄ tiago_assistant/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ stt.py
‚îÇ   ‚îú‚îÄ‚îÄ ollama_client.py
‚îÇ   ‚îú‚îÄ‚îÄ prompts.py
‚îÇ   ‚îú‚îÄ‚îÄ validator.py
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îî‚îÄ‚îÄ models/                   ‚Üê Mod√®les Whisper (t√©l√©charg√©s automatiquement)
    ‚îî‚îÄ‚îÄ ...
```

---

## Mise √† jour

### Mettre √† jour les d√©pendances Python
```bash
pip install --upgrade -r requirements.txt
```

### Mettre √† jour Ollama
```bash
# Windows : R√©installer via winget
winget upgrade Ollama.Ollama

# Linux/macOS : Suivre les instructions sur https://ollama.com
```

### Mettre √† jour un mod√®le Ollama
```bash
ollama pull llama3.2:3b  # Re-t√©l√©charge la derni√®re version
```

---

## Support

En cas de probl√®me :
1. V√©rifiez que tous les pr√©requis sont install√©s
2. Consultez la section D√©pannage ci-dessus
3. V√©rifiez les logs dans le terminal
4. Consultez la documentation : `DOCUMENTATION.md`
